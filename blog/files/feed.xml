<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" 
    xmlns:dc="http://purl.org/dc/elements/1.1/"
    xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
    xmlns:admin="http://webns.net/mvcb/"
    xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
    xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd">
	<channel>
<title>Patrick&#x27;s blog</title><link>https://lipengyuan1994.github.io/index.html</link><description>Patrick&#x27;s blog post</description><dc:language>en</dc:language><language>en</language><dc:creator>Patrick Li</dc:creator><dc:date>2019-12-08T22:04:59-05:00</dc:date><admin:generatorAgent rdf:resource="http://www.realmacsoftware.com/" />
<sy:updatePeriod>hourly</sy:updatePeriod>
<sy:updateFrequency>1</sy:updateFrequency>
<sy:updateBase>2000-01-01T12:00+00:00</sy:updateBase>
<lastBuildDate>Sun, 8 Dec 2019 22:05:46 -0500</lastBuildDate><item><title>Coursera Natural Language Processing in TensorFlow Week 4</title><dc:creator>Patrick Li</dc:creator><category>Data Science</category><category>Mooc</category><dc:date>2019-12-08T22:04:59-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/98461744131ecb120c9fdd29e81377c1-15.html#unique-entry-id-15</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/98461744131ecb120c9fdd29e81377c1-15.html#unique-entry-id-15</guid><content:encoded><![CDATA[What is the name of the method used to tokenize a list of sentences?


...If a sentence has 120 tokens in it, and a Conv1D with 128 filters with a Kernal size of 5 is passed over it, what&rsquo;s the output shape?


...It is the number of dimensions for the vector representing the word encoding


It is the number of dimensions required to encode every word in the corpus


It is the number of words to encode in the embedding


It is the number of letters in the word, denoting the size of the encoding


...If you have a number of sequences of different lengths, how do you ensure that they are understood when fed into a neural network?


...Process them on the input layer of the Neural Network using the pad_sequences property


Specify the input layer of the Neural Network to expect different sizes with dynamic_length


Make sure that they are all the same length using the pad_sequences method of the tokenizer


...When predicting words to generate poetry, the more words predicted the more likely it will end up gibberish. 

...Because you are more likely to hit words not in the training set


...Because the probability that each word matches an existing phrase goes down the more words you create


...What is a major drawback of word-based training for text generation instead of character-based generation?


There is no major drawback, it&rsquo;s always better to do word-based training


Because there are far more words in a typical corpus than characters, it is much more memory intensive


Character based generation is more accurate because there are less characters to predict


Word based generation is more accurate because there is a larger body of words to draw from


...How does an LSTM help understand meaning when words that qualify each other aren&rsquo;t necessarily beside each other in a sentence?


...Values from earlier words can be carried to later ones via a cell state
]]></content:encoded></item><item><title>Coursera Natural Language Processing in TensorFlow Week 3</title><dc:creator>Patrick Li</dc:creator><category>Data Science</category><category>Mooc</category><dc:date>2019-12-08T10:49:38-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/1e6bec86a96c0a806d3719a519ebdc38-14.html#unique-entry-id-14</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/1e6bec86a96c0a806d3719a519ebdc38-14.html#unique-entry-id-14</guid><content:encoded><![CDATA[Why does sequence make a large difference when determining semantics of language?


Because the order in which words appear dictate their meaning


Because the order in which words appear dictate their impact on the meaning of the sentence


Because the order of words doesn&rsquo;t matter


...How do Recurrent Neural Networks help you understand the impact of sequence on meaning?


...They look at the whole sentence at a time


They carry meaning from one cell to the next


They shuffle the words evenly


...How does an LSTM help understand meaning when words that qualify each other aren&rsquo;t necessarily beside each other in a sentence?


They shuffle the words randomly


They load all words into a cell state


Values from earlier words can be carried to later ones via a cell state


...What keras layer type allows LSTMs to look forward and backward in a sentence?


...What&rsquo;s the output shape of a bidirectional LSTM layer with 64 units?


...When stacking LSTMs, how do you instruct an LSTM to feed the next one in the sequence?


...Ensure that return_sequences is set to True on all units


Ensure that return_sequences is set to True only on units that feed to another LSTM


Ensure that they have the same number of units


...If a sentence has 120 tokens in it, and a Conv1D with 128 filters with a Kernal size of 5 is passed over it, what&rsquo;s the output shape?


...What&rsquo;s the best way to avoid overfitting in NLP datasets?
]]></content:encoded></item><item><title>Coursera Natural Language Processing in TensorFlow Week 2</title><dc:creator>Patrick Li</dc:creator><category>Data Science</category><category>Mooc</category><dc:date>2019-12-07T17:01:15-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/5f5bb902c313eca9039751f6c6b7c1ce-13.html#unique-entry-id-13</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/5f5bb902c313eca9039751f6c6b7c1ce-13.html#unique-entry-id-13</guid><content:encoded><![CDATA[What is the name of the TensorFlow library containing common data that you can use to train and test neural networks?


...There is no library of common data sets, you have to use your own


...How many reviews are there in the IMDB dataset and how are they split?


60,000 records, 50/50 train/test split


...50,000 records, 80/20 train/test split


60,000 records, 80/20 train/test split


...How are the labels for the IMDB dataset encoded?


...Reviews encoded as a number 1-5


...It is the number of dimensions for the vector representing the word encoding


It is the number of dimensions required to encode every word in the corpus


It is the number of words to encode in the embedding


It is the number of letters in the word, denoting the size of the encoding


...When tokenizing a corpus, what does the num_words=n parameter do?


It specifies the maximum number of words to be tokenized, and picks the first &lsquo;n&rsquo; words that were tokenized


It specifies the maximum number of words to be tokenized, and stops tokenizing when it reaches n


It errors out if there are more than n distinct words in the corpus


It specifies the maximum number of words to be tokenized, and picks the most common &lsquo;n&rsquo; words


num_words: the maximum number of words to keep, based on word frequency.


...To use word embeddings in TensorFlow, in a sequential layer, what is the name of the class?


...When using IMDB Sub Words dataset, our results in classification were poor. ]]></content:encoded></item><item><title>Coursera Natural Language Processing in TensorFlow Week 1 </title><dc:creator>Patrick Li</dc:creator><category>Mooc</category><category>Data Science</category><dc:date>2019-12-07T11:31:41-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/0c7595d00bde409bb699bc21a3a98aab-12.html#unique-entry-id-12</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/0c7595d00bde409bb699bc21a3a98aab-12.html#unique-entry-id-12</guid><content:encoded><![CDATA[What is the name of the object used to tokenize sentences?


...What is the name of the method used to tokenize a list of sentences?


...Once you have the corpus tokenized, what&rsquo;s the method used to encode a list of sentences to use those tokens?


...When initializing the tokenizer, how to you specify a token to use for unknown words?


...If you don&rsquo;t use a token for out of vocabulary words, what happens at encoding?


...The word isn&rsquo;t encoded, and is skipped in the sequence


The word isn&rsquo;t encoded, and is replaced by a zero in the sequence


...If you have a number of sequences of different lengths, how do you ensure that they are understood when fed into a neural network?


Process them on the input layer of the Neural Netword using the pad_sequences property


...Specify the input layer of the Neural Network to expect different sizes with dynamic_length


Make sure that they are all the same length using the pad_sequences method of the tokenizer


...If you have a number of sequences of different length, and call pad_sequences on them, what&rsquo;s the default result?


They&rsquo;ll get cropped to the length of the shortest sequence


They&rsquo;ll get padded to the length of the longest sequence by adding zeros to the beginning of shorter ones


They&rsquo;ll get padded to the length of the longest sequence by adding zeros to the end of shorter ones


...When padding sequences, if you want the padding to be at the end of the sequence, how do you do it?


Call the padding method of the pad_sequences object, passing it &lsquo;after&rsquo;


Call the padding method of the pad_sequences object, passing it &lsquo;post&rsquo;


Pass padding=&rsquo;post&rsquo; to pad_sequences when initializing it


Pass padding=&rsquo;after&rsquo; to pad_sequences when initializing it
]]></content:encoded></item><item><title>A thorough review of Introduction to TensorFlow for Artificial Intelligence&#x2c; Machine Learning&#x2c; and Deep Learning &#x7c; deeplearning.ai</title><dc:creator>Patrick Li</dc:creator><category>Data Science</category><category>Mooc</category><dc:date>2019-11-30T22:32:32-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/87c0427f79f2740e14342f9d38255c50-11.html#unique-entry-id-11</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/87c0427f79f2740e14342f9d38255c50-11.html#unique-entry-id-11</guid><content:encoded><![CDATA[Course Review: Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning


...		The relationship between this course and Deep Learning Specialization


...This course is the first course in TensorFlow in Practice Specialization offered by deeplearning.ai.   It is an introduction to TensorFlow as the course name implies it.   Intermediate Level, and will lead you to dive into deep learning/ computer vision/ artificial intelligence.


...The relationship between this course and Deep Learning Specialization


I would say deep learning specialization is somehow like a prerequisite for this course.   If the students don&rsquo;t know about deep learning, it would be a little bit hard to understand that the code is really doing.   Because this course is more on practice but doesn&rsquo;t cover too much theory foundations, for example, it wouldn&rsquo;t teach you how to calculate the size of the conventions and pooling layers in detail, but the instructor will provide a link to a specific course.   Let me illustrate this by example: in the week2 video, when Laurence Moroney taught using TensorFlow to build convolutional NN, he provided a link to a lecture in the fourth course of DeepLearningSpecialization.


...It requires students to have experience in Python coding and high school-level math.   It says, &ldquo;Prior machine learning or deep learning knowledge is helpful but not required.&rdquo;   However, from my point of view, the knowledge of deep learning is also required if you want to get understood what the codes are really doing.   If you already finished DeepLearningSpecialization or you already know the fundamental theories in deep learning, but not familiar with TensorFlow, I would recommend this course to you; If you use PyTorch before and want to get your hand dirty with TensorFlow, I would recommend this to you; If you are an ambitious data enthusiast like me, I would definitely recommend this course to you too!   If you are are interested in this course and searching the information about this course and, then don&rsquo;t hesitate, this course is designed for you.


...Laurence Moroney&rsquo;s teaching style is charming, not the same as your professor or other courses provided by Universities. ...  Besides, I love the talks between Laurence and Andrew at the beginning of every week&rsquo;s lecture.   The coding assignments are not challenging, and modesty aside, they are kind of easy for me ( I already finished Andrew&rsquo;s Deep learning Specialization).   Laurence also provided codes in google colab, and it just makes the learning process much more manageable, students can train and test the models in colab very quickly.


And as usual, you can find all materials of this course in my GitHub repo.]]></content:encoded></item><item><title>Coursera Introduction to TensorFlow week3</title><dc:creator>Patrick Li</dc:creator><category>Data Science</category><category>Mooc</category><dc:date>2019-11-30T10:10:05-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/%20.html#unique-entry-id-9</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/%20.html#unique-entry-id-9</guid><content:encoded><![CDATA[Enhancing Vision with Convolutional Neural Networks


...A. A technique to isolate features in images


B. A technique to make images bigger


...A technique to make images smaller


D. A technique to filter out unwanted images


...	2	What is a Pooling?


A. A technique to isolate features in images


B. A technique to combine pictures


...A technique to reduce the information in an image while maintaining features


D. A technique to make images sharper


...	3	How do Convolutions improve image recognition?


A. They make the image clearer


B. They make processing of images faster


...They isolate features in images


D. They make the image smaller


...	4	After passing a 3x3 filter over a 28x28 image, how big will the output be?


...	5	After max pooling a 26x26 image with a 2x2 filter, how big will the output be?


...	6	Applying Convolutions on top of our Deep neural network will make training:


A. It depends on many factors.   It might make your training faster or slower, and a poorly designed Convolutional layer may even be less efficient than a plain DNN!
]]></content:encoded></item><item><title>Coursera Introduction to TensorFlow week2</title><dc:creator>Patrick Li</dc:creator><category>Data Science</category><category>Mooc</category><dc:date>2019-11-30T10:03:53-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/da9606071efd34384b3e5608e488379f-8.html#unique-entry-id-8</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/da9606071efd34384b3e5608e488379f-8.html#unique-entry-id-8</guid><content:encoded><![CDATA[	1	What&rsquo;s the name of the dataset of Fashion images used in this week&rsquo;s code?


...D. Fashion Data


...	2	What do the above mentioned Images look like?


...	3	How many images are in the Fashion MNIST dataset?


...	4	Why are there 10 output neurons?


A. To make it train 10x faster


B. There are 10 different labels


...To make it classify 10x faster


...A. It returns the negative of x


B. It only returns x if x is less than zero


...It only returns x if x is greater than zero


D. For a value x, it returns 1/x


...	6	Why do you split data into training and test sets?


A. To make testing quicker


B. To train a network with previously unseen data


...To make training quicker


D. To test a network with previously unseen data


...	7	What method gets called when an epoch finishes?


A. on_epoch_end


...	8	What parameter to you set in your fit function to tell it to use callbacks?
]]></content:encoded></item><item><title>Coursera Introduction to TensorFlow week1</title><dc:creator>Patrick Li</dc:creator><category>Data Science</category><category>Mooc</category><dc:date>2019-11-30T09:46:50-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/44ece4e1dbcf20d7264d87bbcd2961a5-7.html#unique-entry-id-7</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/44ece4e1dbcf20d7264d87bbcd2961a5-7.html#unique-entry-id-7</guid><content:encoded><![CDATA[	1	The diagram for traditional programming had Rules and Data In, but what came out?


...	2	The diagram for Machine Learning had Answers and Data In, but what came out?


...	3	When I tell a computer what the data represents (i.e. this data is for walking, this data is for running), what is that process called?


A. Programming the Data


...D. Learning the Data


...D. A layer of disconnected neurons


...	5	What does a Loss function do?


A. Measures how good the current &lsquo;guess&rsquo; is


B. Decides to stop training a neural network


...D. Figures out if you win or lose


...	6	What does the optimizer do?


A. Decides to stop training a neural network


B.Figures out how to efficiently compile your code


...Measures how good the current guess is


D. Generates a new and improved guess


...A. The process of getting very close to the correct answer


...	8	What does model.fit do?


A. It trains the neural network to fit one set of values to another


B. It makes a model fit available memory


...D. It determines if your activity is good for your body
]]></content:encoded></item><item><title>Coursera Introduction to TensorFlow week4 </title><dc:creator>Patrick Li</dc:creator><category>Data Science</category><category>Mooc</category><dc:date>2019-11-30T09:37:33-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/6094fdd0289c572ca56833876e4702c4-6.html#unique-entry-id-6</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/6094fdd0289c572ca56833876e4702c4-6.html#unique-entry-id-6</guid><content:encoded><![CDATA[A. It&rsquo;s based on the directory the image is contained in


...What method on the Image Generator is used to normalize the image?


...How did we specify the training size for the images?


A. The training_size parameter on the validation generator


B. target_size parameter on the training generator


...The target_size parameter on the validation generator


D. The training_size parameter on the training generator


...When we specify the input_shape to be (300, 300, 3), what does that mean?


A. Every Image will be 300x300 pixels, and there should be 3 Convolutional Layers


B. Every Image will be 300x300 pixels, with 3 bytes to define color


...There will be 300 horses and 300 humans, loaded in batches of 3


D. There will be 300 images, each size 300, loaded in batches of 3


...If your training data is close to 1.000 accuracy, but your validation data isn&rsquo;t, what&rsquo;s the risk here?


...B. You&rsquo;re overfitting on your validation data


...You&rsquo;re overfitting on your training data


D. You&rsquo;re underfitting on your validation data


...A. In these images, the features may be in different parts of the frame


B. There&rsquo;s a wide variety of horses


...B. There was more condensed information in the images


...D. There was less information in the images
]]></content:encoded></item><item><title>A Thorough Review of Applied Text Mining in Python by University of Michigan</title><dc:creator>Patrick Li</dc:creator><category>Data Science</category><category>Mooc</category><dc:date>2019-11-28T09:12:24-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/0461cce2d67cfa4c1a900cfd011ad403-5.html#unique-entry-id-5</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/0461cce2d67cfa4c1a900cfd011ad403-5.html#unique-entry-id-5</guid><content:encoded><![CDATA[Posted in Toward Data Science in Medium


 Click here.   To read the article.]]></content:encoded></item><item><title>My way to break into Data Science</title><dc:creator>Patrick Li</dc:creator><category>Data Science</category><category>Personal</category><dc:date>2019-11-21T23:23:35-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/e050cb0727ee442cc4ed744b5048f2cc-4.html#unique-entry-id-4</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/e050cb0727ee442cc4ed744b5048f2cc-4.html#unique-entry-id-4</guid><content:encoded><![CDATA[How I, a self-teaching international MS student, lunched a job in DS field. 


Published on Medium : https://link.medium.com/8q0DPrKwO1]]></content:encoded></item><item><title>Why I built this website</title><dc:creator>Patrick Li</dc:creator><category>Personal</category><category>Random Thoughts</category><dc:date>2019-11-19T00:12:13-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/078f1b58b17f3e2543ffd0ce40854c17-3.html#unique-entry-id-3</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/078f1b58b17f3e2543ffd0ce40854c17-3.html#unique-entry-id-3</guid><content:encoded><![CDATA[	&bull;	During last two years, I found a lot of blogs written by data scientists and engineers, these blogs helped me solve my questions in DS and also guided me how to learn DS step by step.   It is the time for me to carry on this awesome traditions of self-teaching data scientists. 


	&bull;	I need a fully-functional repository  to put all my important things together: my all kinds of blogs, learning resources&hellip;.   Using services provided by Blogger or Medium can not satisfy all my needs, and WordPress Pro & Wiz is too expensive. 


But if you want to start building your first blog, WordPress free account might be a good choice for you. 
]]></content:encoded></item><item><title>Applied Text Mining</title><dc:creator>Patrick Li</dc:creator><category>Data Science</category><category>Mooc</category><dc:date>2019-11-16T17:16:42-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/b18186739f4656f2936b541f1b7441a8-1.html#unique-entry-id-1</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/b18186739f4656f2936b541f1b7441a8-1.html#unique-entry-id-1</guid><content:encoded><![CDATA[Applied Text Mining Course completed, Coursera provided by University of Michigan.


<iframe src="https://www.linkedin.com/embed/feed/update/urn:li:share:6601174024452132865" height="449" width="504" frameborder="0" allowfullscreen="" title="Embedded post"></iframe>]]></content:encoded></item><item><title>Unsupervised Learning leaning summary</title><dc:creator>Patrick Li</dc:creator><category>Data Science</category><dc:date>2019-01-12T20:16:51-05:00</dc:date><link>https://lipengyuan1994.github.io/blog/files/c22b612b2a1abb6d27f66e8b4df4498a-0.html#unique-entry-id-0</link><guid isPermaLink="true">https://lipengyuan1994.github.io/blog/files/c22b612b2a1abb6d27f66e8b4df4498a-0.html#unique-entry-id-0</guid><content:encoded><![CDATA[ https://www.linkedin.com/pulse/unsupervised-learning-summary-pengyuan-patrick-li/?  published=t]]></content:encoded></item></channel>
</rss>